{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic data handling and I/O\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Data visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Data preparation\n",
    "from scipy.io import arff\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Feature selection\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Model evaluation and splitting\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Suppress warnings for clean output (optional)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set visual aesthetics for plots (optional)\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (10, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.io import arff\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from mlxtend.feature_selection import ExhaustiveFeatureSelector as EFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Attr1    Attr2    Attr3   Attr4    Attr5    Attr6     Attr7    Attr8  \\\n",
      "0  0.200550  0.37951  0.39641  2.0472  32.3510  0.38825  0.249760  1.33050   \n",
      "1  0.209120  0.49988  0.47225  1.9447  14.7860  0.00000  0.258340  0.99601   \n",
      "2  0.248660  0.69592  0.26713  1.5548  -1.1523  0.00000  0.309060  0.43695   \n",
      "3  0.081483  0.30734  0.45879  2.4928  51.9520  0.14988  0.092704  1.86610   \n",
      "4  0.187320  0.61323  0.22960  1.4063  -7.3128  0.18732  0.187320  0.63070   \n",
      "\n",
      "    Attr9   Attr10  ...    Attr56   Attr57   Attr58    Attr59  Attr60  Attr61  \\\n",
      "0  1.1389  0.50494  ...  0.121960  0.39718  0.87804  0.001924  8.4160  5.1372   \n",
      "1  1.6996  0.49788  ...  0.121300  0.42002  0.85300  0.000000  4.1486  3.2732   \n",
      "2  1.3090  0.30408  ...  0.241140  0.81774  0.76599  0.694840  4.9909  3.9510   \n",
      "3  1.0571  0.57353  ...  0.054015  0.14207  0.94598  0.000000  4.5746  3.6147   \n",
      "4  1.1559  0.38677  ...  0.134850  0.48431  0.86515  0.124440  6.3985  4.3158   \n",
      "\n",
      "    Attr62  Attr63   Attr64  class  \n",
      "0   82.658  4.4158   7.4277      0  \n",
      "1  107.350  3.4000  60.9870      0  \n",
      "2  134.270  2.7185   5.2078      0  \n",
      "3   86.435  4.2228   5.5497      0  \n",
      "4  127.210  2.8692   7.8980      0  \n",
      "\n",
      "[5 rows x 65 columns]\n"
     ]
    }
   ],
   "source": [
    "# Install necessary libraries if needed\n",
    "#%pip install scipy pandas\n",
    "\n",
    "# Load ARFF files using scipy\n",
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "\n",
    "# Load a specific ARFF file (replace with the correct filename as needed)\n",
    "data_1year, meta_1year = arff.loadarff('/Users/poojithramagiri/Desktop/ML Challenges/polish+companies+bankruptcy+data/1year.arff')\n",
    "df_1year = pd.DataFrame(data_1year)\n",
    "\n",
    "# Convert binary classification column to strings for clarity\n",
    "df_1year['class'] = df_1year['class'].apply(lambda x: x.decode('utf-8'))\n",
    "\n",
    "# Check the first few rows\n",
    "print(df_1year.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attr1</th>\n",
       "      <th>Attr2</th>\n",
       "      <th>Attr3</th>\n",
       "      <th>Attr4</th>\n",
       "      <th>Attr5</th>\n",
       "      <th>Attr6</th>\n",
       "      <th>Attr7</th>\n",
       "      <th>Attr8</th>\n",
       "      <th>Attr9</th>\n",
       "      <th>Attr10</th>\n",
       "      <th>...</th>\n",
       "      <th>Attr56</th>\n",
       "      <th>Attr57</th>\n",
       "      <th>Attr58</th>\n",
       "      <th>Attr59</th>\n",
       "      <th>Attr60</th>\n",
       "      <th>Attr61</th>\n",
       "      <th>Attr62</th>\n",
       "      <th>Attr63</th>\n",
       "      <th>Attr64</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.200550</td>\n",
       "      <td>0.37951</td>\n",
       "      <td>0.39641</td>\n",
       "      <td>2.04720</td>\n",
       "      <td>32.3510</td>\n",
       "      <td>0.388250</td>\n",
       "      <td>0.249760</td>\n",
       "      <td>1.330500</td>\n",
       "      <td>1.13890</td>\n",
       "      <td>0.504940</td>\n",
       "      <td>...</td>\n",
       "      <td>0.121960</td>\n",
       "      <td>0.397180</td>\n",
       "      <td>0.87804</td>\n",
       "      <td>0.001924</td>\n",
       "      <td>8.4160</td>\n",
       "      <td>5.1372</td>\n",
       "      <td>82.658</td>\n",
       "      <td>4.4158</td>\n",
       "      <td>7.42770</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.209120</td>\n",
       "      <td>0.49988</td>\n",
       "      <td>0.47225</td>\n",
       "      <td>1.94470</td>\n",
       "      <td>14.7860</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.258340</td>\n",
       "      <td>0.996010</td>\n",
       "      <td>1.69960</td>\n",
       "      <td>0.497880</td>\n",
       "      <td>...</td>\n",
       "      <td>0.121300</td>\n",
       "      <td>0.420020</td>\n",
       "      <td>0.85300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.1486</td>\n",
       "      <td>3.2732</td>\n",
       "      <td>107.350</td>\n",
       "      <td>3.4000</td>\n",
       "      <td>60.98700</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.248660</td>\n",
       "      <td>0.69592</td>\n",
       "      <td>0.26713</td>\n",
       "      <td>1.55480</td>\n",
       "      <td>-1.1523</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.309060</td>\n",
       "      <td>0.436950</td>\n",
       "      <td>1.30900</td>\n",
       "      <td>0.304080</td>\n",
       "      <td>...</td>\n",
       "      <td>0.241140</td>\n",
       "      <td>0.817740</td>\n",
       "      <td>0.76599</td>\n",
       "      <td>0.694840</td>\n",
       "      <td>4.9909</td>\n",
       "      <td>3.9510</td>\n",
       "      <td>134.270</td>\n",
       "      <td>2.7185</td>\n",
       "      <td>5.20780</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.081483</td>\n",
       "      <td>0.30734</td>\n",
       "      <td>0.45879</td>\n",
       "      <td>2.49280</td>\n",
       "      <td>51.9520</td>\n",
       "      <td>0.149880</td>\n",
       "      <td>0.092704</td>\n",
       "      <td>1.866100</td>\n",
       "      <td>1.05710</td>\n",
       "      <td>0.573530</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054015</td>\n",
       "      <td>0.142070</td>\n",
       "      <td>0.94598</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.5746</td>\n",
       "      <td>3.6147</td>\n",
       "      <td>86.435</td>\n",
       "      <td>4.2228</td>\n",
       "      <td>5.54970</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.187320</td>\n",
       "      <td>0.61323</td>\n",
       "      <td>0.22960</td>\n",
       "      <td>1.40630</td>\n",
       "      <td>-7.3128</td>\n",
       "      <td>0.187320</td>\n",
       "      <td>0.187320</td>\n",
       "      <td>0.630700</td>\n",
       "      <td>1.15590</td>\n",
       "      <td>0.386770</td>\n",
       "      <td>...</td>\n",
       "      <td>0.134850</td>\n",
       "      <td>0.484310</td>\n",
       "      <td>0.86515</td>\n",
       "      <td>0.124440</td>\n",
       "      <td>6.3985</td>\n",
       "      <td>4.3158</td>\n",
       "      <td>127.210</td>\n",
       "      <td>2.8692</td>\n",
       "      <td>7.89800</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7022</th>\n",
       "      <td>0.018371</td>\n",
       "      <td>0.47410</td>\n",
       "      <td>-0.13619</td>\n",
       "      <td>0.60839</td>\n",
       "      <td>-18.4490</td>\n",
       "      <td>0.018371</td>\n",
       "      <td>0.018371</td>\n",
       "      <td>0.972030</td>\n",
       "      <td>1.01210</td>\n",
       "      <td>0.460840</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011909</td>\n",
       "      <td>0.039866</td>\n",
       "      <td>0.98809</td>\n",
       "      <td>0.274140</td>\n",
       "      <td>73.5050</td>\n",
       "      <td>79.2370</td>\n",
       "      <td>31.268</td>\n",
       "      <td>11.6730</td>\n",
       "      <td>5.14890</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7023</th>\n",
       "      <td>-0.013359</td>\n",
       "      <td>0.58354</td>\n",
       "      <td>-0.02265</td>\n",
       "      <td>0.92896</td>\n",
       "      <td>-42.2320</td>\n",
       "      <td>-0.013359</td>\n",
       "      <td>-0.015036</td>\n",
       "      <td>0.562890</td>\n",
       "      <td>0.98904</td>\n",
       "      <td>0.328470</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011082</td>\n",
       "      <td>-0.040671</td>\n",
       "      <td>1.01110</td>\n",
       "      <td>0.805920</td>\n",
       "      <td>10.5990</td>\n",
       "      <td>7.1740</td>\n",
       "      <td>94.092</td>\n",
       "      <td>3.8792</td>\n",
       "      <td>1.75720</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7024</th>\n",
       "      <td>0.006338</td>\n",
       "      <td>0.50276</td>\n",
       "      <td>0.43923</td>\n",
       "      <td>1.87360</td>\n",
       "      <td>9.7417</td>\n",
       "      <td>0.006338</td>\n",
       "      <td>0.012022</td>\n",
       "      <td>0.983560</td>\n",
       "      <td>1.00830</td>\n",
       "      <td>0.494490</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008258</td>\n",
       "      <td>0.012817</td>\n",
       "      <td>0.99174</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.4700</td>\n",
       "      <td>6.0759</td>\n",
       "      <td>51.019</td>\n",
       "      <td>7.1542</td>\n",
       "      <td>62.00100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7025</th>\n",
       "      <td>-0.041643</td>\n",
       "      <td>0.84810</td>\n",
       "      <td>-0.12852</td>\n",
       "      <td>0.57485</td>\n",
       "      <td>-121.9200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.036795</td>\n",
       "      <td>0.179010</td>\n",
       "      <td>0.42138</td>\n",
       "      <td>0.151820</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.232720</td>\n",
       "      <td>-0.274290</td>\n",
       "      <td>0.98788</td>\n",
       "      <td>3.593100</td>\n",
       "      <td>39.7030</td>\n",
       "      <td>3.1420</td>\n",
       "      <td>261.850</td>\n",
       "      <td>1.3939</td>\n",
       "      <td>0.51005</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7026</th>\n",
       "      <td>0.014946</td>\n",
       "      <td>0.94648</td>\n",
       "      <td>0.03211</td>\n",
       "      <td>1.03630</td>\n",
       "      <td>-20.5810</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015260</td>\n",
       "      <td>0.056357</td>\n",
       "      <td>2.96940</td>\n",
       "      <td>0.053341</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015705</td>\n",
       "      <td>0.280210</td>\n",
       "      <td>0.97443</td>\n",
       "      <td>1.179200</td>\n",
       "      <td>15.0360</td>\n",
       "      <td>4.1741</td>\n",
       "      <td>108.640</td>\n",
       "      <td>3.3599</td>\n",
       "      <td>35.11800</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7027 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Attr1    Attr2    Attr3    Attr4     Attr5     Attr6     Attr7  \\\n",
       "0     0.200550  0.37951  0.39641  2.04720   32.3510  0.388250  0.249760   \n",
       "1     0.209120  0.49988  0.47225  1.94470   14.7860  0.000000  0.258340   \n",
       "2     0.248660  0.69592  0.26713  1.55480   -1.1523  0.000000  0.309060   \n",
       "3     0.081483  0.30734  0.45879  2.49280   51.9520  0.149880  0.092704   \n",
       "4     0.187320  0.61323  0.22960  1.40630   -7.3128  0.187320  0.187320   \n",
       "...        ...      ...      ...      ...       ...       ...       ...   \n",
       "7022  0.018371  0.47410 -0.13619  0.60839  -18.4490  0.018371  0.018371   \n",
       "7023 -0.013359  0.58354 -0.02265  0.92896  -42.2320 -0.013359 -0.015036   \n",
       "7024  0.006338  0.50276  0.43923  1.87360    9.7417  0.006338  0.012022   \n",
       "7025 -0.041643  0.84810 -0.12852  0.57485 -121.9200  0.000000 -0.036795   \n",
       "7026  0.014946  0.94648  0.03211  1.03630  -20.5810  0.000000  0.015260   \n",
       "\n",
       "         Attr8    Attr9    Attr10  ...    Attr56    Attr57   Attr58    Attr59  \\\n",
       "0     1.330500  1.13890  0.504940  ...  0.121960  0.397180  0.87804  0.001924   \n",
       "1     0.996010  1.69960  0.497880  ...  0.121300  0.420020  0.85300  0.000000   \n",
       "2     0.436950  1.30900  0.304080  ...  0.241140  0.817740  0.76599  0.694840   \n",
       "3     1.866100  1.05710  0.573530  ...  0.054015  0.142070  0.94598  0.000000   \n",
       "4     0.630700  1.15590  0.386770  ...  0.134850  0.484310  0.86515  0.124440   \n",
       "...        ...      ...       ...  ...       ...       ...      ...       ...   \n",
       "7022  0.972030  1.01210  0.460840  ...  0.011909  0.039866  0.98809  0.274140   \n",
       "7023  0.562890  0.98904  0.328470  ... -0.011082 -0.040671  1.01110  0.805920   \n",
       "7024  0.983560  1.00830  0.494490  ...  0.008258  0.012817  0.99174  0.000000   \n",
       "7025  0.179010  0.42138  0.151820  ... -0.232720 -0.274290  0.98788  3.593100   \n",
       "7026  0.056357  2.96940  0.053341  ...  0.015705  0.280210  0.97443  1.179200   \n",
       "\n",
       "       Attr60   Attr61   Attr62   Attr63    Attr64  class  \n",
       "0      8.4160   5.1372   82.658   4.4158   7.42770      0  \n",
       "1      4.1486   3.2732  107.350   3.4000  60.98700      0  \n",
       "2      4.9909   3.9510  134.270   2.7185   5.20780      0  \n",
       "3      4.5746   3.6147   86.435   4.2228   5.54970      0  \n",
       "4      6.3985   4.3158  127.210   2.8692   7.89800      0  \n",
       "...       ...      ...      ...      ...       ...    ...  \n",
       "7022  73.5050  79.2370   31.268  11.6730   5.14890      1  \n",
       "7023  10.5990   7.1740   94.092   3.8792   1.75720      1  \n",
       "7024  10.4700   6.0759   51.019   7.1542  62.00100      1  \n",
       "7025  39.7030   3.1420  261.850   1.3939   0.51005      1  \n",
       "7026  15.0360   4.1741  108.640   3.3599  35.11800      1  \n",
       "\n",
       "[7027 rows x 65 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing & Feature selection \n",
    "# Convert target variable to numeric\n",
    "df_1year['class'] = df_1year['class'].astype(int)\n",
    "\n",
    "# Impute missing values using median\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "df_imputed = pd.DataFrame(imputer.fit_transform(df_1year), columns=df_1year.columns)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(df_imputed.drop(columns=['class']))\n",
    "y = df_imputed['class'].values\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and perform exhaustive feature selection\n",
    "efs = EFS(RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "          min_features=1,\n",
    "          max_features=5,  # Adjust the max_features depending on the dataset size and computational power\n",
    "          scoring='accuracy',\n",
    "          print_progress=True,\n",
    "          cv=5)  # Changed to cv=5 for a more robust cross-validation\n",
    "\n",
    "efs.fit(X_train, y_train)\n",
    "\n",
    "# Print the indices of the best feature subset\n",
    "print('Best subset (indices):', efs.best_idx_)\n",
    "print('Best subset (names):', [df_imputed.columns[i] for i in efs.best_idx_])\n",
    "\n",
    "# Optional: Fit model on selected features and assess model performance\n",
    "selected_X_train = X_train[:, efs.best_idx_]\n",
    "selected_X_test = X_test[:, efs.best_idx_]\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(selected_X_train, y_train)\n",
    "predictions = model.predict(selected_X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(f'Accuracy with selected features: {accuracy:.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
